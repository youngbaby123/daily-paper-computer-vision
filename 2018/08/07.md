**2018-08-07**

这篇文章介绍两篇 ECCV 2018最新的 paper，一篇提出新的网格自动编码的卷积神经网络，用于生成3D人脸；另一篇提出新的RFNet，实现看图说话（image caption）。

# 3D Face

**《Generating 3D faces using Convolutional Mesh Autoencoders》**

**ECCV 2018**

Abstract：人脸的3D表示（representations）对于计算机视觉问题是有用的，例如3D面部跟踪和从图像重建，以及诸如角色生成和动画的图形应用。传统模型使用线性子空间或高阶张量概括来学习面部的潜在表示（latent representation）。由于这种线性，它们无法捕获极端变形和非线性表达式。为了解决这个问题，我们引入了一个多功能模型（versatile model），该模型使用网格表面上的光谱卷积来学习面部的非线性表示。我们引入了网格采样操作，这种操作能够实现分层网格表示，捕获模型中多个尺度的形状和表达的非线性变化。在variational setting中，我们的模型从多元高斯分布中采样不同的逼真3D人脸。我们的训练数据包括在12个不同subjects中捕获的20,466个极端表情网格。尽管训练数据有限，但我们训练的模型优于最先进的面部模型，重建误差降低50％，而参数减少75％。我们还表明，用我们的自动编码器替换现有最先进的人脸模型的表达空间，可以实现更低的重建误差。

arXiv：https://arxiv.org/abs/1807.10267

github：https://github.com/anuragranj/coma

# Image Captioning

**《Recurrent Fusion Network for Image Captioning》**

**ECCV 2018** 

Abstract：最近，看图说话（Image captioning）已经取得了很大进展，并且所有最先进的模型都采用了编码器 - 解码器框架。在此框架下，输入图像由卷积神经网络（CNN）编码，然后通过递归神经网络（RNN）转换为自然语言。依赖于该框架的现有模型仅使用一种CNN，例如ResNet或Inception-X，其仅从一个特定视点描述图像内容。因此，不能全面地理解输入图像的语义含义，这限制了captioning的性能。在本文中，为了利用来自多个编码器的补充信息，我们提出了一种用于处理看图说话的新型循环融合网络（RFNet）。我们模型中的融合过程可以利用图像编码器的输出之间的相互作用，然后为解码器生成新的紧凑但信息丰富的表示。 MSCOCO数据集上的实验证明了我们提出的RFNet的有效性，它为看图说话（image caption）提供了一种新的先进技术。

arXiv：https://arxiv.org/abs/1807.09986

注：Image Caption挺有意思的！CNN和RNN完美结合~
