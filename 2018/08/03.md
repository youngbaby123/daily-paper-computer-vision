**2018-08-03**

这篇文章介绍两篇 ECCV 2018最新的 paper，一篇提出新的基于卷积神经网络（CNN）的密度估计方法来解决图像中人群计数的问题；另一篇是提出实时立体匹配的端到端深度架构StereoNet，实现了亚像素匹配精度的深度预测。

# Crowd Counting

**《Iterative Crowd Counting》**

**ECCV 2018**

Abstract：在这项工作中，我们解决了图像中人群计数的问题。我们提出了一种基于卷积神经网络（CNN）的密度估计方法来解决这个问题。一次性预测高分辨率密度图是一项具有挑战性的任务。因此，我们提出了一个用于生成高分辨率密度图的两分支CNN架构，其中第一个分支生成低分辨率密度图，第二个分支包含来自第一个分支的低分辨率预测和特征图以生成高分辨率密度图。我们还提出了我们方法的多阶段扩展，其中管道中的每个阶段都使用来自所有先前阶段的预测。与目前最佳的人群计数方法的实证比较表明，我们的方法在三个具有挑战性的人群计数基准上实现了最低的平均绝对误差：Shanghaitech，WorldExpo'10和UCF数据集。

arXiv：https://arxiv.org/abs/1807.09959

# Depth Prediction

**《StereoNet: Guided Hierarchical Refinement for Real-Time Edge-Aware Depth Prediction》**

**ECCV 2018**

Abstract：本文介绍了StereoNet，这是第一个用于实时立体匹配的端到端深度架构，在NVidia Titan X上以60 fps运行，可生成高质量，边缘保留，无量化（quantization-free）的视差图。本文的一个重要创新点是网络实现了亚像素匹配精度，而不是传统立体匹配方法的精度。This allows us to achieve real-time performance by using a very low resolution cost volume that encodes all the information needed to achieve high disparity precision.。通过采用学习的边缘感知上采样功能来实现空间精度。我们的模型使用Siamese网络从左右图像中提取特征。在非常低分辨率的cost volume中计算视差的第一估计，然后分层地通过使用紧凑的像素到像素细化网络的学习的上采样函数来重新引入高频细节。利用颜色输入作为指导，该功能（function）能够产生高质量的边缘感知输出。我们在多个基准测试中获得了最佳的结果。

arXiv：https://arxiv.org/abs/1807.08865

注：哇，实时立体匹配啊！