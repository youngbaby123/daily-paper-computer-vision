**2018-07-27**

这篇文章介绍两篇 ECCV 2018最新的 paper，一篇提出对目标周围的视觉上下文建模，来实现目标检测数据集的增广；另一篇是提出一种综合贝叶斯模型，该模型连贯地推理观察到的图像，身份，名称的部分知识以及每个观察的情境背景。

# Data Augmentation

**《Modeling Visual Context is Key to Augmenting Object Detection Datasets》**

ECCV 2018

Abstract：众所周知，用于深度神经网络的数据增广（data augmentation）对于训练视觉识别系统是十分重要的。通过人为增加训练样本的数量，它有助于减少过度拟合并改善泛化。对于物体检测（object detection），用于数据增强的经典方法包括生成通过基本几何变换和原始训练图像的颜色变化获得的图像。在这项工作中，我们更进一步，利用 segmentation annotations 来增加训练数据上存在的对象实例的数量。为了使这种方法获得成功，我们证明，适当地建模对象周围的视觉上下文（ visual context ）对于将它们放置在正确的环境中至关重要。否则，我们会发现之前的策略确实会受到伤害。通过我们的上下文（context）模型，当VOC'12基准测试中很少有标记示例可用时，我们实现了显著的平均精度改进。

arXiv：https://arxiv.org/abs/1807.07428

# Face Recognition

**《From Face Recognition to Models of Identity: A Bayesian Approach to Learning about Unknown Identities from Unsupervised Data》**

ECCV 2018

Abstract：当前的面部识别系统可以在各种成像条件下稳健地识别身份。在这些系统中，通过分类到从监督身份标记获得的已知身份来执行识别。这个当前范例存在两个问题：（1）current systems are unable to benefit from unlabelled data which may be available in large quantities; （2）当前系统将成功识别等同于给定输入图像的标记。另一方面，人类会对完全无监督的个体进行识别，即使没有能够命名该个体，也要认识到他们之前见过的人的身份。我们如何超越当前的分类范式，更加人性化地理解身份？我们提出了一个综合的贝叶斯模型，该模型连贯地推理观察到的图像，身份，名称的部分知识以及每个观察的情境背景。我们的模型不仅对已知身份获得了良好的识别性能，它还可以从无监督数据中发现新身份，并学习将身份与不同情境联系起来，这取决于哪些身份倾向于一起观察。此外，提出的半监督组件不仅能够处理熟人的名字，而且还能够处理统一框架中未标记的熟悉面孔和完全陌生人。

arXiv：https://arxiv.org/abs/1807.07872