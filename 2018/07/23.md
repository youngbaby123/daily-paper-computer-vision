**2018-07-23**

这篇文章介绍两篇 ECCV 2018最新的 paper，一篇提出卷积块注意力模块，它可以无缝地集成到任何CNN架构中；另一篇是利用 GAN技术实现多视图3D重建。

# CNN

**《CBAM: Convolutional Block Attention Module》**

**ECCV 2018**

Abstract：我们提出了卷积块注意力模块（CBAM，Convolutional Block Attention Module ），这是一种用于前馈卷积神经网络的简单而有效的注意力（attention）模块。给定中间特征图，我们的模块沿着两个单独的维度（通道和空间）顺序地（sequentially）推断注意力图，然后将注意力图乘以输入特征图以进行自适应特征细化。由于CBAM是一个轻量级的通用模块，它可以无缝地集成到任何CNN架构中，代价可以忽略不计，并且可以与基本CNN一起进行端到端的训练。 我们通过对ImageNet-1K，MS~COCO检测和VOC~2007检测数据集的大量实验来验证我们的CBAM。 我们的实验表明，各种模型在分类和检测性能方面均有一定的改进，证明了CBAM的广泛适用性。 代码和模型将随后公开提供。

arXiv：[链接：https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)

注：很棒的论文，相信可以帮助一波同学写论文（划水）

# Multi-View Reconstruction

**《Specular-to-Diffuse Translation for Multi-View Reconstruction》**

**ECCV 2018** 

Abstract：大多数多视图3D重建算法，特别是当使用来自阴影的形状提示时，假设对象外观主要是漫射的（predominantly diffuse）。为了缓解这种限制，我们引入了S2Dnet，一种生成的对抗网络，用于将具有镜面反射的物体的多个视图转换为漫反射（ diffuse），从而可以更有效地应用多视图重建方法。我们的网络将无监督的图像到图像转换扩展到多视图“镜面到漫反射”的转换。为了在多个视图中保留对象外观，我们引入了一个多视图一致性损失（MVC，Multi-View Coherence loss），用于评估视图转换后局部patches的相似性和faithfulness。我们的MVC损失确保在图像到图像转换下保留多视图图像之间的局部对应的相似性。因此，与几种单视图 baseline 技术相比，我们的网络产生了明显更好的结果。此外，我们使用基于物理的渲染精心设计并生成大型综合训练数据集。在测试过程中，我们的网络仅将原始光泽图像作为输入，无需额外信息，如分割掩模或光照估计。结果表明，使用我们的网络过滤的图像可以显著地改善多视图重建。我们还展示了在现实世界训练和测试数据上的出色表现。

arXiv：[链接：https://arxiv.org/abs/1807.05439](https://arxiv.org/abs/1807.05439)